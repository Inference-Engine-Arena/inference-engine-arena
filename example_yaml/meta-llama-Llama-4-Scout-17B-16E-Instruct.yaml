runs:
  - engine:
      - type: sglang
        model: meta-llama/Llama-4-Scout-17B-16E-Instruct
        args: "--tp 8 --mem-fraction-static 0.7 --cuda-graph-max-bs 16 --context-length 1000000"
        env: {SGL_ENABLE_JIT_DEEPGEMM: "1"}
    benchmarks:
      - type: conversational_short
        dataset-name: random
        random-input-len: 100
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 1000
        request-rate: 10
      - type: conversational_medium
        dataset-name: random
        random-input-len: 1000
        random-output-len: 100
        random-prefix-len: 2000
        num-prompts: 500
        request-rate: 5
      - type: conversational_long
        dataset-name: random
        random-input-len: 5000
        random-output-len: 100
        random-prefix-len: 7000
        num-prompts: 200
        request-rate: 2
      - type: summarization
        dataset-name: random
        random-input-len: 12000
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: write_essay
        dataset-name: random
        random-input-len: 100
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: rewrite_essay
        dataset-name: random
        random-input-len: 12000
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2

  - engine:
      - type: sglang
        model: meta-llama/Llama-4-Scout-17B-16E-Instruct
        args: "--tp 8 --mem-fraction-static 0.7 --cuda-graph-max-bs 16 --context-length 1000000 --enable-torch-compile"
        env: {}
    benchmarks:
      - type: conversational_short
        dataset-name: random
        random-input-len: 100
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 1000
        request-rate: 10
      - type: conversational_medium
        dataset-name: random
        random-input-len: 1000
        random-output-len: 100
        random-prefix-len: 2000
        num-prompts: 500
        request-rate: 5
      - type: conversational_long
        dataset-name: random
        random-input-len: 5000
        random-output-len: 100
        random-prefix-len: 7000
        num-prompts: 200
        request-rate: 2
      - type: summarization
        dataset-name: random
        random-input-len: 12000
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: write_essay
        dataset-name: random
        random-input-len: 100
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: rewrite_essay
        dataset-name: random
        random-input-len: 12000
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2

  - engine:
      - type: sglang
        model: meta-llama/Llama-4-Scout-17B-16E-Instruct
        args: "--tp 8 --mem-fraction-static 0.7 --cuda-graph-max-bs 16 --context-length 1000000"
        env: {}
    benchmarks:
      - type: conversational_short
        dataset-name: random
        random-input-len: 100
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 1000
        request-rate: 10
      - type: conversational_medium
        dataset-name: random
        random-input-len: 1000
        random-output-len: 100
        random-prefix-len: 2000
        num-prompts: 500
        request-rate: 5
      - type: conversational_long
        dataset-name: random
        random-input-len: 5000
        random-output-len: 100
        random-prefix-len: 7000
        num-prompts: 200
        request-rate: 2
      - type: summarization
        dataset-name: random
        random-input-len: 12000
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: write_essay
        dataset-name: random
        random-input-len: 100
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: rewrite_essay
        dataset-name: random
        random-input-len: 12000
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2


  - engine:
      - type: vllm
        model: meta-llama/Llama-4-Scout-17B-16E-Instruct
        args: "--tensor-parallel-size 8 --max-model-len 1000000"
        env: {VLLM_DISABLE_COMPILE_CACHE: "1"}
    benchmarks:
      - type: conversational_short
        dataset-name: random
        random-input-len: 100
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 1000
        request-rate: 10
      - type: conversational_medium
        dataset-name: random
        random-input-len: 1000
        random-output-len: 100
        random-prefix-len: 2000
        num-prompts: 500
        request-rate: 5
      - type: conversational_long
        dataset-name: random
        random-input-len: 5000
        random-output-len: 100
        random-prefix-len: 7000
        num-prompts: 200
        request-rate: 2
      - type: summarization
        dataset-name: random
        random-input-len: 12000
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: write_essay
        dataset-name: random
        random-input-len: 100
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: rewrite_essay
        dataset-name: random
        random-input-len: 12000
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2

  - engine:
      - type: vllm
        model: meta-llama/Llama-4-Scout-17B-16E-Instruct
        args: "--tensor-parallel-size 8 --max-model-len 1000000"
        env: {}
    benchmarks:
      - type: conversational_short
        dataset-name: random
        random-input-len: 100
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 1000
        request-rate: 10
      - type: conversational_medium
        dataset-name: random
        random-input-len: 1000
        random-output-len: 100
        random-prefix-len: 2000
        num-prompts: 500
        request-rate: 5
      - type: conversational_long
        dataset-name: random
        random-input-len: 5000
        random-output-len: 100
        random-prefix-len: 7000
        num-prompts: 200
        request-rate: 2
      - type: summarization
        dataset-name: random
        random-input-len: 12000
        random-output-len: 100
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: write_essay
        dataset-name: random
        random-input-len: 100
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2
      - type: rewrite_essay
        dataset-name: random
        random-input-len: 12000
        random-output-len: 3000
        random-prefix-len: 0
        num-prompts: 200
        request-rate: 2