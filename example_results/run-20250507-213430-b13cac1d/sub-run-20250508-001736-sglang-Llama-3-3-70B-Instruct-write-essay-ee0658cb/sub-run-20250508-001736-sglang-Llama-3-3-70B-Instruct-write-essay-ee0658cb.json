{
  "id": "sub-run-20250508-001736-sglang-Llama-3-3-70B-Instruct-write-essay-ee0658cb",
  "parent_run_id": "run-20250507-213430-b13cac1d",
  "engine": {
    "name": "sglang",
    "type": "sglang",
    "model": "example/Llama-3.3-70B-Instruct",
    "status": "running",
    "container_id": "f09cc62be722",
    "converted_dtype": "bfloat16",
    "converted_quantization": null,
    "engine_args": {
      "model-path": "meta-llama/Llama-3.3-70B-Instruct",
      "host": "0.0.0.0",
      "tp": 4,
      "trust-remote-code": true
    },
    "env_vars": {},
    "full_engine_args": {
      "model_path": "meta-llama/Llama-3.3-70B-Instruct",
      "tokenizer_path": "meta-llama/Llama-3.3-70B-Instruct",
      "tokenizer_mode": "auto",
      "skip_tokenizer_init": false,
      "enable_tokenizer_batch_encode": false,
      "load_format": "auto",
      "trust_remote_code": true,
      "dtype": "auto",
      "kv_cache_dtype": "auto",
      "quantization": null,
      "quantization_param_path": null,
      "context_length": null,
      "device": "cuda",
      "served_model_name": "meta-llama/Llama-3.3-70B-Instruct",
      "chat_template": null,
      "completion_template": null,
      "is_embedding": false,
      "revision": null,
      "host": "0.0.0.0",
      "port": 30000,
      "mem_fraction_static": 0.85,
      "max_running_requests": null,
      "max_total_tokens": null,
      "chunked_prefill_size": null,
      "max_prefill_tokens": 16384,
      "schedule_policy": "fcfs",
      "schedule_conservativeness": 1.0,
      "cpu_offload_gb": 0,
      "page_size": 1,
      "tp_size": 4,
      "pp_size": 1,
      "max_micro_batch_size": 2049,
      "stream_interval": 1,
      "stream_output": false,
      "random_seed": 332441702,
      "constrained_json_whitespace_pattern": null,
      "watchdog_timeout": 300,
      "dist_timeout": null,
      "download_dir": null,
      "base_gpu_id": 0,
      "gpu_id_step": 1,
      "log_level": "info",
      "log_level_http": null,
      "log_requests": false,
      "log_requests_level": 0,
      "show_time_cost": false,
      "enable_metrics": false,
      "decode_log_interval": 40,
      "api_key": null,
      "file_storage_path": "sglang_storage",
      "enable_cache_report": false,
      "reasoning_parser": null,
      "dp_size": 1,
      "load_balance_method": "round_robin",
      "ep_size": 1,
      "dist_init_addr": null,
      "nnodes": 1,
      "node_rank": 0,
      "json_model_override_args": "{}",
      "lora_paths": null,
      "max_loras_per_batch": 8,
      "lora_backend": "triton",
      "attention_backend": "fa3",
      "sampling_backend": "flashinfer",
      "grammar_backend": "xgrammar",
      "speculative_algorithm": null,
      "speculative_draft_model_path": null,
      "speculative_num_steps": null,
      "speculative_eagle_topk": null,
      "speculative_num_draft_tokens": null,
      "speculative_accept_threshold_single": 1.0,
      "speculative_accept_threshold_acc": 1.0,
      "speculative_token_map": null,
      "enable_double_sparsity": false,
      "ds_channel_config_path": null,
      "ds_heavy_channel_num": 32,
      "ds_heavy_token_num": 256,
      "ds_heavy_channel_type": "qk",
      "ds_sparse_decode_threshold": 4096,
      "disable_radix_cache": false,
      "disable_cuda_graph": false,
      "disable_cuda_graph_padding": false,
      "enable_nccl_nvls": false,
      "disable_outlines_disk_cache": false,
      "disable_custom_all_reduce": false,
      "enable_multimodal": null,
      "disable_overlap_schedule": false,
      "enable_mixed_chunk": false,
      "enable_dp_attention": false,
      "enable_ep_moe": false,
      "enable_deepep_moe": false,
      "deepep_mode": "auto",
      "enable_torch_compile": false,
      "torch_compile_max_bs": 32,
      "cuda_graph_max_bs": null,
      "cuda_graph_bs": null,
      "torchao_config": "",
      "enable_nan_detection": false,
      "enable_p2p_check": false,
      "triton_attention_reduce_in_fp32": false,
      "triton_attention_num_kv_splits": 8,
      "num_continuous_decode_steps": 1,
      "delete_ckpt_after_loading": false,
      "enable_memory_saver": false,
      "allow_auto_truncate": false,
      "enable_custom_logit_processor": false,
      "tool_call_parser": null,
      "enable_hierarchical_cache": false,
      "hicache_ratio": 2.0,
      "hicache_size": 0,
      "hicache_write_policy": "write_through_selective",
      "flashinfer_mla_disable_ragged": false,
      "warmups": null,
      "moe_dense_tp_size": null,
      "n_share_experts_fusion": 0,
      "disable_chunked_prefix_cache": true,
      "disable_fast_image_processor": false,
      "debug_tensor_dump_output_folder": null,
      "debug_tensor_dump_input_file": null,
      "debug_tensor_dump_inject": false,
      "disaggregation_mode": "null",
      "disaggregation_bootstrap_port": 8998,
      "disaggregation_transfer_backend": "mooncake",
      "disaggregation_ib_device": null,
      "status": "ready",
      "max_total_num_tokens": 420422,
      "max_req_input_len": 131066,
      "use_mla_backend": false,
      "last_gen_throughput": 0.0,
      "version": "0.4.6.post2"
    },
    "full_env_vars": {
      "PATH": "/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin",
      "CUDA_VERSION": "12.4.1.003",
      "CUDA_DRIVER_VERSION": "550.54.15",
      "CUDA_CACHE_DISABLE": "1",
      "NVIDIA_REQUIRE_JETPACK_HOST_MOUNTS": "",
      "_CUDA_COMPAT_PATH": "/usr/local/cuda/compat",
      "ENV": "/etc/shinit_v2",
      "BASH_ENV": "/etc/bash.bashrc",
      "SHELL": "/bin/bash",
      "NVIDIA_REQUIRE_CUDA": "cuda>=9.0",
      "NCCL_VERSION": "2.21.5",
      "CUBLAS_VERSION": "12.4.5.8",
      "CUFFT_VERSION": "11.2.1.3",
      "CURAND_VERSION": "10.3.5.147",
      "CUSPARSE_VERSION": "12.3.1.170",
      "CUSOLVER_VERSION": "11.6.1.9",
      "CUTENSOR_VERSION": "2.0.1.2",
      "NPP_VERSION": "12.2.5.30",
      "NVJPEG_VERSION": "12.3.1.117",
      "CUDNN_VERSION": "9.1.0.70",
      "TRT_VERSION": "8.6.3.1+cuda12.2.2.009",
      "TRTOSS_VERSION": "23.11",
      "NSIGHT_SYSTEMS_VERSION": "2024.2.1.106",
      "NSIGHT_COMPUTE_VERSION": "2024.1.1.4",
      "DALI_VERSION": "1.36.0",
      "DALI_BUILD": "13435171",
      "POLYGRAPHY_VERSION": "0.49.8",
      "TRANSFORMER_ENGINE_VERSION": "1.5",
      "LD_LIBRARY_PATH": "/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64",
      "NVIDIA_VISIBLE_DEVICES": "all",
      "NVIDIA_DRIVER_CAPABILITIES": "compute,utility,video",
      "NVIDIA_PRODUCT_NAME": "Triton Server Base",
      "GDRCOPY_VERSION": "2.3.1-1",
      "HPCX_VERSION": "2.18",
      "MOFED_VERSION": "5.4-rdmacore39.0",
      "OPENUCX_VERSION": "1.16.0",
      "OPENMPI_VERSION": "4.1.7",
      "RDMACORE_VERSION": "39.0",
      "OPAL_PREFIX": "/opt/hpcx/ompi",
      "OMPI_MCA_coll_hcoll_enable": "0",
      "LIBRARY_PATH": "/usr/local/cuda/lib64/stubs:",
      "NVIDIA_TRITON_SERVER_BASE_VERSION": "24.04",
      "NVIDIA_BUILD_ID": "90085237",
      "DEBIAN_FRONTEND": "interactive"
    },
    "version": "0.4.6.post2",
    "endpoint": "http://localhost:30000",
    "gpu_info": {
      "success": true,
      "container_id": "f09cc62be722",
      "container_stats": {
        "cpu_usage": "343.90%",
        "memory_usage": "15.33GiB / 1007GiB",
        "memory_percent": "1.52%"
      },
      "num_gpus": 4,
      "gpus": [
        {
          "index": 0,
          "name": "NVIDIA H100 80GB HBM3",
          "memory_total": 81559.0,
          "memory_used": 77431.0,
          "utilization": 0.0
        },
        {
          "index": 1,
          "name": "NVIDIA H100 80GB HBM3",
          "memory_total": 81559.0,
          "memory_used": 77863.0,
          "utilization": 0.0
        },
        {
          "index": 2,
          "name": "NVIDIA H100 80GB HBM3",
          "memory_total": 81559.0,
          "memory_used": 77861.0,
          "utilization": 0.0
        },
        {
          "index": 3,
          "name": "NVIDIA H100 80GB HBM3",
          "memory_total": 81559.0,
          "memory_used": 76279.0,
          "utilization": 0.0
        }
      ]
    }
  },
  "model": "example/Llama-3.3-70B-Instruct",
  "benchmark": {
    "type": "write_essay",
    "config": {
      "dataset-name": "random",
      "random-input-len": 100,
      "random-output-len": 3000,
      "random-prefix-len": 0,
      "num-prompts": 100,
      "request-rate": 8
    },
    "command": "python /scratch/inference-engine-arena/src/benchmarks/benchmark_serving.py --base-url http://localhost:30000 --model meta-llama/Llama-3.3-70B-Instruct --backend sglang --trust-remote-code --served-model-name  --dataset-name random --random-input-len 100 --random-output-len 3000 --random-prefix-len 0 --num-prompts 100 --request-rate 8 --save-result --result-dir results/run-20250507-213430-b13cac1d/sub-run-20250508-001736-sglang-Llama-3-3-70B-Instruct-write-essay-ee0658cb --result-filename raw_result.json",
    "namespace_params": {
      "backend": "sglang",
      "base_url": "http://localhost:30000",
      "host": "127.0.0.1",
      "port": 8000,
      "endpoint": "/v1/completions",
      "dataset_name": "random",
      "dataset_path": null,
      "max_concurrency": null,
      "model": "meta-llama/Llama-3.3-70B-Instruct",
      "tokenizer": null,
      "use_beam_search": false,
      "num_prompts": 100,
      "logprobs": null,
      "request_rate": 8.0,
      "burstiness": 1.0,
      "seed": 0,
      "trust_remote_code": true,
      "disable_tqdm": false,
      "profile": false,
      "save_result": true,
      "save_detailed": false,
      "metadata": null,
      "result_dir": "results/run-20250507-213430-b13cac1d/sub-run-20250508-001736-sglang-Llama-3-3-70B-Instruct-write-essay-ee0658cb",
      "result_filename": "raw_result.json",
      "ignore_eos": false,
      "percentile_metrics": "ttft",
      "metric_percentiles": "99",
      "goodput": null,
      "sonnet_input_len": 550,
      "sonnet_output_len": 150,
      "sonnet_prefix_len": 200,
      "sharegpt_output_len": null,
      "random_input_len": 100,
      "random_output_len": 3000,
      "random_range_ratio": 1.0,
      "random_prefix_len": 0,
      "hf_subset": null,
      "hf_split": null,
      "hf_output_len": null,
      "tokenizer_mode": "auto",
      "served_model_name": ""
    }
  },
  "start_time": "2025-05-08T00:17:36.366605",
  "end_time": "2025-05-08T00:19:50.838273",
  "duration_seconds": 134.471668,
  "success": true,
  "metrics": {
    "input_throughput": 129.25999785728368,
    "output_throughput": 1786.877284379305,
    "mean_ttft_ms": 76.76638095988892,
    "median_ttft_ms": 76.42574951751158,
    "std_ttft_ms": 10.441979871376565,
    "p99_ttft_ms": 102.29834920843135,
    "mean_tpot_ms": 22.28153798820509,
    "median_tpot_ms": 21.86524677792371,
    "std_tpot_ms": 1.1135411182219177,
    "p99_tpot_ms": 25.323937081489806,
    "mean_itl_ms": 21.791119336168727,
    "median_itl_ms": 21.26821002457291,
    "std_itl_ms": 3.6283113659837505,
    "p99_itl_ms": 32.832180346595095,
    "request_throughput": 1.2925999785728375,
    "request_goodput": 0,
    "duration": 77.36345478700241,
    "num_prompts": 100,
    "total_input_tokens": 10000,
    "total_output_tokens": 138239
  },
  "exit_code": 0,
  "stdout": "INFO 05-08 00:17:39 [__init__.py:239] Automatically detected platform cuda.\nNamespace(backend='sglang', base_url='http://localhost:30000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='meta-llama/Llama-3.3-70B-Instruct', tokenizer=None, use_beam_search=False, num_prompts=100, logprobs=None, request_rate=8.0, burstiness=1.0, seed=0, trust_remote_code=True, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/run-20250507-213430-b13cac1d/sub-run-20250508-001736-sglang-Llama-3-3-70B-Instruct-write-essay-ee0658cb', result_filename='raw_result.json', ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=100, random_output_len=3000, random_range_ratio=1.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, tokenizer_mode='auto', served_model_name='', lora_modules=None)\nStarting initial single prompt test run...\nInitial test run completed. Starting main benchmark run...\nTraffic request rate: 8.0\nBurstiness factor: 1.0 (Poisson process)\nMaximum request concurrency: None\n============ Serving Benchmark Result ============\nSuccessful requests:                     100       \nBenchmark duration (s):                  77.36     \nTotal input tokens:                      10000     \nTotal generated tokens:                  138239    \nRequest throughput (req/s):              1.29      \nOutput token throughput (tok/s):         1786.88   \nTotal Token throughput (tok/s):          1916.14   \n---------------Time to First Token----------------\nMean TTFT (ms):                          76.77     \nMedian TTFT (ms):                        76.43     \nP99 TTFT (ms):                           102.30    \n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          22.28     \nMedian TPOT (ms):                        21.87     \nP99 TPOT (ms):                           25.32     \n---------------Inter-token Latency----------------\nMean ITL (ms):                           21.79     \nMedian ITL (ms):                         21.27     \nP99 ITL (ms):                            32.83     \n==================================================\n",
  "stderr": "\n  0%|          | 0/100 [00:00<?, ?it/s]\n  1%|          | 1/100 [00:00<00:10,  9.32it/s]\n  2%|▏         | 2/100 [00:04<04:44,  2.90s/it]\n  3%|▎         | 3/100 [00:05<02:54,  1.80s/it]\n  4%|▍         | 4/100 [00:05<02:03,  1.28s/it]\n  5%|▌         | 5/100 [00:06<01:26,  1.10it/s]\n  6%|▌         | 6/100 [00:06<01:07,  1.38it/s]\n  8%|▊         | 8/100 [00:07<00:45,  2.04it/s]\n  9%|▉         | 9/100 [00:07<00:38,  2.37it/s]\n 10%|█         | 10/100 [00:07<00:31,  2.86it/s]\n 11%|█         | 11/100 [00:07<00:26,  3.35it/s]\n 12%|█▏        | 12/100 [00:08<00:29,  2.96it/s]\n 15%|█▌        | 15/100 [00:08<00:19,  4.40it/s]\n 16%|█▌        | 16/100 [00:08<00:22,  3.69it/s]\n 17%|█▋        | 17/100 [00:09<00:19,  4.21it/s]\n 19%|█▉        | 19/100 [00:09<00:16,  4.78it/s]\n 20%|██        | 20/100 [00:09<00:23,  3.43it/s]\n 21%|██        | 21/100 [00:10<00:22,  3.50it/s]\n 23%|██▎       | 23/100 [00:10<00:18,  4.12it/s]\n 24%|██▍       | 24/100 [00:11<00:24,  3.09it/s]\n 25%|██▌       | 25/100 [00:12<00:34,  2.19it/s]\n 27%|██▋       | 27/100 [00:12<00:23,  3.05it/s]\n 28%|██▊       | 28/100 [00:13<00:38,  1.86it/s]\n 29%|██▉       | 29/100 [00:14<00:36,  1.92it/s]\n 30%|███       | 30/100 [00:14<00:29,  2.36it/s]\n 33%|███▎      | 33/100 [00:14<00:16,  4.14it/s]\n 34%|███▍      | 34/100 [00:14<00:14,  4.48it/s]\n 35%|███▌      | 35/100 [00:15<00:17,  3.62it/s]\n 37%|███▋      | 37/100 [00:15<00:13,  4.53it/s]\n 38%|███▊      | 38/100 [00:15<00:12,  4.80it/s]\n 39%|███▉      | 39/100 [00:16<00:20,  3.01it/s]\n 40%|████      | 40/100 [00:16<00:22,  2.72it/s]\n 42%|████▏     | 42/100 [00:16<00:14,  4.04it/s]\n 43%|████▎     | 43/100 [00:17<00:16,  3.51it/s]\n 44%|████▍     | 44/100 [00:17<00:18,  3.07it/s]\n 47%|████▋     | 47/100 [00:18<00:14,  3.70it/s]\n 48%|████▊     | 48/100 [00:18<00:14,  3.56it/s]\n 49%|████▉     | 49/100 [00:18<00:12,  3.98it/s]\n 50%|█████     | 50/100 [00:19<00:14,  3.40it/s]\n 51%|█████     | 51/100 [00:19<00:14,  3.49it/s]\n 52%|█████▏    | 52/100 [00:19<00:12,  3.93it/s]\n 54%|█████▍    | 54/100 [00:19<00:09,  5.07it/s]\n 55%|█████▌    | 55/100 [00:20<00:13,  3.29it/s]\n 56%|█████▌    | 56/100 [00:21<00:24,  1.78it/s]\n 57%|█████▋    | 57/100 [00:23<00:34,  1.23it/s]\n 58%|█████▊    | 58/100 [00:26<01:02,  1.49s/it]\n 60%|██████    | 60/100 [01:05<06:12,  9.32s/it]\n 61%|██████    | 61/100 [01:07<04:54,  7.54s/it]\n 62%|██████▏   | 62/100 [01:07<03:34,  5.65s/it]\n 63%|██████▎   | 63/100 [01:07<02:34,  4.18s/it]\n 64%|██████▍   | 64/100 [01:07<01:50,  3.07s/it]\n 66%|██████▌   | 66/100 [01:08<01:04,  1.91s/it]\n 67%|██████▋   | 67/100 [01:08<00:48,  1.48s/it]\n 68%|██████▊   | 68/100 [01:09<00:40,  1.26s/it]\n 69%|██████▉   | 69/100 [01:09<00:30,  1.01it/s]\n 71%|███████   | 71/100 [01:09<00:17,  1.67it/s]\n 72%|███████▏  | 72/100 [01:10<00:16,  1.66it/s]\n 74%|███████▍  | 74/100 [01:10<00:10,  2.50it/s]\n 75%|███████▌  | 75/100 [01:10<00:09,  2.69it/s]\n 76%|███████▌  | 76/100 [01:11<00:09,  2.60it/s]\n 77%|███████▋  | 77/100 [01:11<00:08,  2.84it/s]\n 79%|███████▉  | 79/100 [01:11<00:06,  3.48it/s]\n 80%|████████  | 80/100 [01:12<00:05,  3.42it/s]\n 82%|████████▏ | 82/100 [01:12<00:04,  4.45it/s]\n 83%|████████▎ | 83/100 [01:12<00:04,  3.97it/s]\n 84%|████████▍ | 84/100 [01:12<00:03,  4.32it/s]\n 85%|████████▌ | 85/100 [01:13<00:03,  4.41it/s]\n 86%|████████▌ | 86/100 [01:13<00:04,  3.04it/s]\n 87%|████████▋ | 87/100 [01:14<00:04,  2.96it/s]\n 88%|████████▊ | 88/100 [01:14<00:05,  2.33it/s]\n 89%|████████▉ | 89/100 [01:14<00:03,  2.87it/s]\n 90%|█████████ | 90/100 [01:15<00:03,  2.72it/s]\n 91%|█████████ | 91/100 [01:15<00:02,  3.19it/s]\n 92%|█████████▏| 92/100 [01:15<00:02,  2.71it/s]\n 93%|█████████▎| 93/100 [01:16<00:02,  3.24it/s]\n 94%|█████████▍| 94/100 [01:16<00:01,  3.68it/s]\n 95%|█████████▌| 95/100 [01:16<00:01,  3.01it/s]\n 97%|█████████▋| 97/100 [01:17<00:00,  3.48it/s]\n 99%|█████████▉| 99/100 [01:17<00:00,  5.16it/s]\n100%|██████████| 100/100 [01:17<00:00,  1.29it/s]\n"
}